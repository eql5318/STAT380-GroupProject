---
title: "Group Project"
authors: "Ed Lawrence, Bobby Dodge, Henry Harrison"
date: "2024-12-10"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}

library(tidyverse)
library(ggplot2)
library(randomForest)
library(dplyr)
library(rpart)
library(rattle)
library(e1071)
library(caret)

CODMAPS <- read.csv("CODMaps.csv")
CODGameModes <- read.csv("CODGameModes.csv")
CODGames_p1_380 <- read.csv("CODGames_p1_380.csv")
CODGames_p2_380 <- read.csv("CODGames_p2_380.csv")
```

## Task 1

In Task 1, we are tasked with answering a research question that asks "Which maps are most likely win the Map Vote when they are an option?" To answer this, our group's end goal will be to provide a bar chart plotting winning percentage, and pick out the maps with the highest winning percentages. Our first steps will involve resolving certain data issues: we are given data from two different players, player 1 and player 2. We will combine this data using a full_join into object CODGames_P1andP2. This will be an important object going forward.

Second, we will isolate only the columns necessary to answering this question, which are Map1, Map2, Choice, and MapVote. This is Step 2. For Step 3, we will remove cases where values are missing. If you look at the raw data, you will notice that while each row has a value for "Choice," there was not always two options nor a vote. Since our research question asks for which maps most frequently one votes, we will remove cases missing data, where a vote never took place. Steps 4 and 5 attempt to discern a tie vote from a vote where one map won outright. To determine which votes ended up being ties, our group will look at the MapVote column which tells us the vote totals between Map1 and Map2 in string format "# to #." We intend to isolate each of these numbers and convert them into numeric values, which will be accomplished by separating the string into two different columns ("result_left" and "result_right") with just the numbers in their appropriate data type, while cutting out the unnecessary " to " part. From there in Step 5, we will create a new column called "tie" with possible values of "yes" or "no" if the respective values of result_left and result_right match, then tie column took on the value "yes," "no" otherwise.

In Step 6, our group will take a plug-and-chug approach to resolving typos, misspellings, misinterpretations, and trailing blanks. In the console, we will run the command "table(CODGames_P1andP2$Map1/Map2/Choice)" to pick out individually cases of these errors. We will then match each error with it's intended Map name, and correct mistakes in each column using map names by invoking three mutate commands.

Transitioning to the data analysis phase, in step 7, our group will tabulate the frequency of each map in Map1 and Map2 columns from CODGames_P1andP2 dataframe. If the map occurred in either Map1 or Map2, that means it was a potential candidate voted on by the players in that case. The total number of times each Map was a candidate will be calculated by summing up the Map's frequency in Map1 column with the Map's frequency in Map2 Column. This total frequency number will be stored in dataframe Full_MapCandidateFrequency.

Next, our group will determine how many times each map one outright, which will be stored in dataframe Map_Winning_Frequency. Since it is impossible to win outright if there was a tie, we will remove cases where ties occurred. The column "Choice" indicated the winner of the vote, and so we will simply calculate how many times each map occurred in that column.

From there we will have two data frames: Full_MapCandidateFrequency and Map_Winning_Frequency. Each have frequency's related to each of the 28 possible map options. These data frames will be joined into a larger dataframe called Full_MapFrequency. Finally, our group will create one last dataframe called Map_Winning_Percentages which will include the Map name, as well as the value of it's winning frequency divided by the number of times it appeared as a candidate.

For the data visualization, we will create a vertical bar chart that plots each maps rate of winning as a possible candidate. The three Maps with the highest bars will be chosen to answer the research qustion of which maps are most likely to win when they are an option. We will also create a supplementary vertical bar chart that plots the number of times the map associated with "Map1" outright and by tie-default versus the map chosen as the "Map2" option.

### Task 1: Data Preparation Phase

```{r}

# Step 1: Combine p1 and p2

CODGames_P1andP2 <- full_join(CODGames_p1_380, CODGames_p2_380)

# Step 2: Select only columns relevant to task 1 research question

CODGames_P1andP2 <- CODGames_P1andP2 %>%
  select(Map1, Map2, Choice, MapVote)

# Step 3: Remove Cases where values are missing

CODGames_P1andP2 <- CODGames_P1andP2 %>%
  filter(Map1 != "")

# Step 4: Convert MapVote into two separate Numeric Columns

CODGames_P1andP2 <- CODGames_P1andP2 %>%
  separate(MapVote, into = c("left", "right"), sep = " to ") %>%
  mutate(
    result_left = as.numeric(left),
    result_right = as.numeric(right)
  )

CODGames_P1andP2$left <- NULL
CODGames_P1andP2$right <- NULL

# Step 5: Check if there was a tie or not in the vote

CODGames_P1andP2 <- CODGames_P1andP2 %>%
  mutate("tie" = ifelse(result_left == result_right, "Yes", "No"))

# Step 6: Correct the names of the maps to account for misspellings/trailing blanks using as_tibble, mutate, and amatch

CODGames_P1andP2 <- CODGames_P1andP2 %>%
  mutate(Map1 = case_when(Map1 %in% c("Collateral", "Collateral Striek", "Collaterol Strike") ~ "Collateral Strike",
                          Map1 == "Deprogam" ~ "Deprogram",
                          Map1 == "Drive-in" ~ "Drive-In",
                          Map1 == "Jungle " ~ "Jungle",
                          Map1 == "Miami " ~ "Miami",
                          Map1 == "Miami Stirke" ~ "Miami Strike",
                          Map1 %in% c("Raid ", "Riad") ~ "Raid",
                          Map1 %in% c("Ruah", "Rush ") ~ "Rush",
                          Map1 == "Zoo " ~ "Zoo",
                          TRUE ~ Map1)) %>%
  mutate(Map2 = case_when(Map2 == "Amrada Strike" ~ "Armada Strike",
                          Map2 == "Collateral" ~ "Collateral Strike",
                          Map2 == "Drive-in" ~ "Drive-In",
                          Map2 %in% c("Miami Sstrike", "Miami Stirke") ~ "Miami Strike",
                          Map2 == "Nuketown '84 Halloween" ~ "Nuketown '84",
                          Map2 == "yamantau" ~ "Yamantau",
                          TRUE ~ Map2)) %>%
  mutate(Choice = case_when(Choice %in% c("APocalypse", "Apocolypse") ~ "Apocalypse",
                            Choice %in% c("Collateral", "Collaterel Strike") ~ "Collateral Strike",
                            Choice == "Deisel" ~ "Diesel",
                            Choice == "Drive-in" ~ "Drive-In",
                            Choice == "Nuketown '84 Halloween" ~ "Nuketown '84",
                            TRUE ~ Choice))
```

### Task 1 - Data Analysis Phase

#### Finding out how many times each Map was a candidate

```{r}

# Step 7: Finding Candidate Frequency for Map1 & Map2, then congregating that information together using left_join

Map1_CandidateFrequency <- CODGames_P1andP2 %>%
  group_by(Map1) %>%
  summarize(count1 = n())

Map2_CandidateFrequency <- CODGames_P1andP2 %>%
  group_by(Map2) %>%
  summarize(count2 = n())

Full_MapCandidateFrequency <- left_join(Map1_CandidateFrequency, Map2_CandidateFrequency, by = c("Map1" = "Map2")) %>%
  mutate(TotalCandidateFrequency = count1 + count2)

Full_MapCandidateFrequency$count1 <- NULL

Full_MapCandidateFrequency$count2 <- NULL

Full_MapCandidateFrequency

```

#### Finding out how many times each map won outright (no ties)

```{r}

# Step 8

Map_Winning_frequency <- CODGames_P1andP2 %>%
  filter(tie == "No") %>%
  group_by(Choice) %>%
  summarize(count = n())

Map_Winning_frequency

```

#### Joining Map winning frequency data with Map candidacy frequency data

```{r}

# Step 9

Full_MapFrequency <- left_join(Full_MapCandidateFrequency, Map_Winning_frequency, by = c("Map1" = "Choice"))

Map_WinningPercentages <- Full_MapFrequency %>%
  mutate(winning_pct = count/TotalCandidateFrequency)

Map_WinningPercentages$count <- NULL
Map_WinningPercentages$TotalCandidateFrequency <- NULL

Map_WinningPercentages

```

### Task 1 - Data Visualization

#### Visualizing winning percentage by Map

```{r}

ggplot(Map_WinningPercentages, aes(x = Map1, y = winning_pct)) +
  geom_bar(stat = "identity", fill = "skyblue", color = "black") +
  labs(title = "Winning Percentage by Map",
       x = "Map",
       y = "Winning Percentage") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

```

From this visualization, we observe that Maps like Raid, Crossroads Strike, and Nuketown '84 have the highest vote winning rates when offered as a choice, whereas maps like Echelon, WMD, and Miami are among the lowest. Therefore to answer the research question Raid, Nuketown '84 and Crossroads Strike are the three maps most likely to win the map vote when they are an option?

#### Visualizing rate of victory by option (Map1, Map2, or Map1 by tie-default)

```{r}

# Step 8: Create Bar Chart Showing Map1 Winning By Tie vs Not, or Map2

# Create New column showing which map won the vote, and if they won by tie

CODGames_P1andP2 <- CODGames_P1andP2 %>%
  mutate(
    MapWins = case_when(
      Map1 == Choice & tie == "No" ~ "Map1 without Tie",
      Map1 == Choice & tie == "Yes" ~ "Map1 with Tie",
      Map2 == Choice ~ "Map2"
    )
  )

# Create Simple Bar Plot for COD Map Choice

counts <- table(CODGames_P1andP2$MapWins)
barplot(counts, main="COD Map Choice",
   xlab="Map Choice", col=rgb(0.8,0.1,0.1,0.6))

```

Based off this Visualization, it appears that the Map2 choice won outright more frequently than Map1, however when Map1's victories both outright and via ties were tabulated together, that number outperformed Map2 win rate.

### Task 2

```{r}

library(dplyr)
library(ggplot2)

# Step 1: Load the datasets
p1_data <- CODGames_p1_380
p2_data <- CODGames_p2_380

# Step 2: Inspect data structure and summary
str(p1_data)
str(p2_data)

# Step 3: Data cleaning
# Remove rows with missing values in critical columns
p1_cleaned <- p1_data %>% filter(!is.na(Map1), !is.na(Map2), !is.na(MapVote))
p2_cleaned <- p2_data %>% filter(!is.na(Map1), !is.na(Map2), !is.na(MapVote))

# Standardize map names by trimming whitespaces and converting to lowercase
p1_cleaned <- p1_cleaned %>%
  mutate(
    Map1 = tolower(trimws(Map1)),
    Map2 = tolower(trimws(Map2)),
    Choice = tolower(trimws(Choice))
  )

p2_cleaned <- p2_cleaned %>%
  mutate(
    Map1 = tolower(trimws(Map1)),
    Map2 = tolower(trimws(Map2)),
    Choice = tolower(trimws(Choice))
  )

# Step 4: Combine datasets
combined_data <- bind_rows(p1_cleaned, p2_cleaned)


# Step 5: Calculate win probabilities with tie handling

# Identify outright wins (exclude ties where Map1 was chosen by default)
outright_wins <- combined_data %>%
  filter(MapVote != "tie" | Choice != Map1) %>%
  group_by(Choice) %>%
  summarise(wins = n()) %>%
  rename(map = Choice)

# Count total appearances for each map (regardless of ties)
appearances <- combined_data %>%
  pivot_longer(cols = c(Map1, Map2), names_to = "position", values_to = "map") %>%
  group_by(map) %>%
  summarise(appearances = n())

# Merge wins and appearances to calculate probabilities
map_probabilities <- appearances %>%
  left_join(outright_wins, by = "map") %>%
  mutate(
    wins = ifelse(is.na(wins), 0, wins),  # Handle maps with no outright wins
    win_probability = wins / appearances
  )

# Step 6: Visualization (unchanged)
map_probabilities <- map_probabilities %>%
  arrange(desc(win_probability))

ggplot(map_probabilities, aes(x = reorder(map, -win_probability), y = win_probability)) +
  geom_bar(stat = "identity", fill = "steelblue") +
  labs(
    title = "Win Probability of Each Map (Excluding Default Wins)",
    x = "Map Name",
    y = "Win Probability"
  ) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

```

## Task 3

#### Step 1: Combining Player dataframes again so all attributes are available
```{r}

CODGames_P1andP2 <- full_join(CODGames_p1_380, CODGames_p2_380)

```

#### Step 2: Cleaning GameType column

In this step, we resolve some discrepancies with how game type names are written. Certain games are prefaced with "HC - ." These code removes this prefix to consolidate game types into four categories.

```{r}

CODGames_P1andP2 <- CODGames_P1andP2 %>%
  mutate(GameType = case_when(GameType == "HC - TDM" ~ "TDM",
                          GameType == "HC - Hardpoint" ~ "Hardpoint",
                          GameType == "HC - Domination" ~ "Domination",
                          GameType == "HC - Kill Confirmed" ~ "Kill Confirmed",
                          TRUE ~ GameType))

```

#### Step 3: EDA, Analyzing Distributions of GameType, Score, and TotalXP

##### 3.1: TotalXP

```{r}

# TotalXP Summary Statistics

print("TotalXP Summary Statistics")
summary(CODGames_P1andP2$TotalXP)

# DensityPlot for TotalXP

options(scipen = 999)

ggplot(CODGames_P1andP2, aes(x = TotalXP)) +
  geom_density(fill = "blue", alpha = 0.4) +
  labs(title = "Density Plot of TotalXP",
       x = "TotalXP",
       y = "Density") +
  theme_minimal()

```

In this density plot, we see that TotalXP is skewed slightly right. We also observe from the summary statistics that the median and average TotalXP are both right around 15,000, with a range for TotalXP of over 40,000.

#### Step 4:

##### 3.2: Score

```{r}

# Score Summary Statistics

print("Score Summary Statistics")
summary(CODGames_P1andP2$Score)

# DensityPlot for Score

ggplot(CODGames_P1andP2, aes(x = Score)) +
  geom_density(fill = "blue", alpha = 0.4) +
  labs(title = "Density Plot of Score",
       x = "Score",
       y = "Density") +
  theme_minimal()

```

In this density plot, we see that the distribution of Score is also skewed slightly right. Additionally, we observe from the summary statistics that the median and average Score are both right around 2,900, with a range for Score of about 9,600. These statistics are noticeably less than what was observed for TotalXP.

##### 3.3: GameType

```{r}

# Bar Chart for GameType

ggplot(CODGames_P1andP2, aes(x = GameType)) +
  geom_bar(fill = "skyblue", color = "black") +
  labs(title = "Frequency of GameType",
       x = "GameType",
       y = "Count") +
  theme_minimal()

```

In this visualization, we observe that TDM and Hardpoint are the predominant GameTypes among the Player 1 and 2 data available. Between these two types, TDM outnumbers Hardpoint 2:1 in frequency.

##### 3.4 Visualizing Relationship between TotalXP, Score, GameType

For this we will do charts with two lines, Score and TotalXP, facet wrapped by GameType.

```{r}
ggplot(CODGames_P1andP2, aes(x = Score, y = TotalXP)) +
  geom_smooth(color = "blue", method = "loess", se = FALSE) +
  facet_wrap(~ GameType, scales = "free") +
  labs(title = "Relationship between TotalXP, Score and GameType",
       x = "Score",
       y = "TotalXP") +
  theme_minimal()
```

In this visualization, we have plotted Score vs TotalXP when grouped by each category of GameType. In each grouping, we see a strong positive relationship between Score and TotalXP. That being said, in the hardpoint, TotalXP appears to go down once Score exceeds 7500. Since hardpoint is one of the 2 main GameTypes, this will be an interesting dynamic to consider going forward.

#### Step 4: Build model for TotalXP based off Score and GameType

```{r}

model <- lm(TotalXP ~ Score + GameType, data = CODGames_P1andP2)

summary(model)

```

Upon accounting for Score, this model was tasked with answering a research question to determine how TotalXP is affected by GameType. Based off our EDA, as well as the low P-value associated with score, it is clear that Score is a strong indicator of TotalXP, which explains why accounting for this variable was prudent. However, once Score was accounted for, we observe a relatively low R-squared value (~.34) for the relationship between GameType and TotalXP. This model performance result suggests that while Score was a strong indicator of TotalXP, GameType is a relatively poor indicator. Thus, to answer the research question, after accounting for Score, GameType does not considerably affect TotalXP.

## Task 4

Research Question: What factors best contribute to the player winning a match?

Methods used: Random Forest, Support Vector Machines

## Random Forest Method:

### Step 1: Prepare Data

```{r}
# Part a: Combine player 1 and player 2 data

CODGames_P1andP2 <- full_join(CODGames_p1_380, CODGames_p2_380)

# Step 2: Select columns relevant to task 4 research question

CODGames_P1andP2 <- CODGames_P1andP2 %>%
  select(Choice, Eliminations, Deaths, Score, Damage, PrimaryWeapon, GameType, Result)

# Step 3: Remove Cases where values are missing

CODGames_P1andP2 <- CODGames_P1andP2 %>%
  filter(Choice != "" & PrimaryWeapon != "")

# Step 4: Fix spellings of map choice names

CODGames_P1andP2 <- CODGames_P1andP2 %>%
  mutate(Choice = case_when(Choice %in% c("APocalypse", "Apocolypse") ~ "Apocalypse",
                            Choice %in% c("Collateral", "Collaterel Strike") ~ "Collateral Strike",
                            Choice == "Deisel" ~ "Diesel",
                            Choice == "Drive-in" ~ "Drive-In",
                            Choice == "Nuketown '84 Halloween" ~ "Nuketown '84",
                            TRUE ~ Choice))

# Step 5: Create a new column for player 1 or 2 winning a match from 
# split result column into two to make win column

CODGames_P1andP2 <- CODGames_P1andP2 %>%
  separate(Result, into = c("Result_Player", "Result_Opposing"), sep = "-") %>%
  mutate(
    result_player = as.numeric(Result_Player),
    result_opposing = as.numeric(Result_Opposing)
  )

CODGames_P1andP2 <- CODGames_P1andP2 %>%
  mutate("Win" = ifelse(result_player > result_opposing, "Yes", "No"))

# Step 6: Convert Win and Choice to factor

CODGames_P1andP2$Win <- as.factor(CODGames_P1andP2$Win)

CODGames_P1andP2$Choice <- as.factor(CODGames_P1andP2$Choice)


# Step 7: Perform Training/Validation Split
set.seed(123)
CODGames_P1andP2Ind <- sample(1:nrow(CODGames_P1andP2), floor(0.85*nrow(CODGames_P1andP2)))

CODGames_P1andP2 <- CODGames_P1andP2[, c("Choice", "Eliminations", "Deaths", "Score", "Damage", "PrimaryWeapon", "GameType", "Win")]

#Step 8: Create Train and Validations
Train <- CODGames_P1andP2[CODGames_P1andP2Ind, ]
Validation <- CODGames_P1andP2[-CODGames_P1andP2Ind, ]
```

### Step 2:  Pruning the Tree
```{r}
#Part a:  Using a complexity parameter (cp) value of 0.001, grow the tree. 
set.seed(123)
fullTree <- rpart(Win ~ ., 
                  method = "class",
                  data = Train,
                  cp = 0.01,
                  xval = 10)

#Part b: Display the cptable
fullTree$cptable
```

### Step 3 - Plot the tree
```{r}
fancyRpartPlot(fullTree, cex = 0.5)
```

### Step 4: Visualize the results of the cross validation procedure. 
```{r}
plotcp(fullTree)
```

### Step 5: What is the optimal value of the complexity parameter based on minimizing the cross validation error? 
```{r}
#Part a: Determine the row of cptable containing smallest CV error
cpRow <- which.min(fullTree$cptable[ , "xerror"])

#Part b: Determine optimal value of cp 
cpChoiceMin <- fullTree$cptable[ , "CP"][cpRow]

#Part c: Display the choice
cpChoiceMin
```

### Step 6: Find the optimal value of the complexity parameter based on the 1se rule
```{r}
#Part a: Determine the row of cptable containing smallest CV error
cpRow <- which.min(fullTree$cptable[ , "xerror"])

# Part b: Calculate min(xerror) + xstd
target <- fullTree$cptable[ , "xerror"][cpRow] +fullTree$cptable[ , "xstd"][cpRow]

#Part c: Determine which xerror values are less than target and select first such value
cpRow1se <- which(fullTree$cptable[ , "xerror"] < target)[1]

cpChoice1se <- fullTree$cptable[ , "CP"][cpRow1se]

#Part d: Display the choice
cpChoice1se
```

### Step 7: Prune the Tree
```{r}
#Part a: Prune the true
prunedTree <- prune(fullTree, cp=cpChoice1se)

#Part b: View the pruned tree
fancyRpartPlot(prunedTree, cex=0.65)
```

### Step 8: Find the validation set accuracy from Pruned Tree
```{r}
#Part a: Obtain the predicted classes
prunedPred <- predict(prunedTree, newdata = Validation,
                      type = "class")
  
#Part b: Calculate the accuracy
mean(prunedPred == Validation$Win)

```
## Support Vector Machines (SVMs) Method:

### Step 1: Convert factors to numeric for SVM
```{r}
CODGames_P1andP2$Choice <- as.factor(CODGames_P1andP2$Choice)
CODGames_P1andP2$PrimaryWeapon <- as.factor(CODGames_P1andP2$PrimaryWeapon)
```

### Step 2: Split data into train and validation sets
```{r}
set.seed(123)
train_indices <- sample(1:nrow(CODGames_P1andP2), floor(0.85 * nrow(CODGames_P1andP2)))
Train <- CODGames_P1andP2[train_indices, ]
Validation <- CODGames_P1andP2[-train_indices, ]
```

### Step 3: Train SVM Model
```{r}
svm_model <- svm(Win ~ ., data = Train, kernel = "radial")
```

### Step 4: Predict on Validation Set
```{r}
svm_pred <- predict(svm_model, newdata = Validation)
```
## Step 5: Get the most import factor for "Win"
```{r}
#Part a: Fit SVM model with RFE
control <- rfeControl(functions=rfFuncs, method="cv", number=10)
rfe_result <- rfe(Train %>% select(-Win), Train$Win, sizes=1:ncol(Train)-1, rfeControl=control)

#Part b: Get the important features
important_features <- predictors(rfe_result)
important_features
```

### Step 6: Evaluate Accuracy
```{r}
accuracy_svm <- mean(svm_pred == Validation$Win)
accuracy_svm
```

Analysis:

Both of the methods being used shows that "Deaths" was the most important factor for "Win". From the accuracy predictions of each model, we can see that SVM allows for a higher accuracy compared to the random forest model.
