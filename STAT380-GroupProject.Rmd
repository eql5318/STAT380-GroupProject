---
title: "Group Project"
authors: "Ed Lawrence, Bobby Dodge, Henry Harrison"
date: "2024-12-10"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}

library(tidyverse)
library(ggplot2)
library(randomForest)
library(dplyr)
library(rpart)
library(rattle)
library(e1071)
library(caret)

CODMAPS <- read.csv("CODMaps.csv")
CODGameModes <- read.csv("CODGameModes.csv")
CODGames_p1_380 <- read.csv("CODGames_p1_380.csv")
CODGames_p2_380 <- read.csv("CODGames_p2_380.csv")
```

## Task 1

In Task 1, we are tasked with answering a research question that asks "Which maps are most likely win the Map Vote when they are an option?" To answer this, our group's end goal will be to provide a bar chart plotting winning percentage, and pick out the maps with the highest winning percentages. Our first steps will involve resolving certain data issues: we are given data from two different players, player 1 and player 2. We will combine this data using a full_join into object CODGames_P1andP2. This will be an important object going forward.

Second, we will isolate only the columns necessary to answering this question, which are Map1, Map2, Choice, and MapVote. This is Step 2. For Step 3, we will remove cases where values are missing. If you look at the raw data, you will notice that while each row has a value for "Choice," there was not always two options nor a vote. Since our research question asks for which maps most frequently one votes, we will remove cases missing data, where a vote never took place. Steps 4 and 5 attempt to discern a tie vote from a vote where one map won outright. To determine which votes ended up being ties, our group will look at the MapVote column which tells us the vote totals between Map1 and Map2 in string format "# to #." We intend to isolate each of these numbers and convert them into numeric values, which will be accomplished by separating the string into two different columns ("result_left" and "result_right") with just the numbers in their appropriate data type, while cutting out the unnecessary " to " part. From there in Step 5, we will create a new column called "tie" with possible values of "yes" or "no" if the respective values of result_left and result_right match, then tie column took on the value "yes," "no" otherwise.

In Step 6, our group will take a plug-and-chug approach to resolving typos, misspellings, misinterpretations, and trailing blanks. In the console, we will run the command "table(CODGames_P1andP2$Map1/Map2/Choice)" to pick out individually cases of these errors. We will then match each error with it's intended Map name, and correct mistakes in each column using map names by invoking three mutate commands.

Transitioning to the data analysis phase, in step 7, our group will tabulate the frequency of each map in Map1 and Map2 columns from CODGames_P1andP2 dataframe. If the map occurred in either Map1 or Map2, that means it was a potential candidate voted on by the players in that case. The total number of times each Map was a candidate will be calculated by summing up the Map's frequency in Map1 column with the Map's frequency in Map2 Column. This total frequency number will be stored in dataframe Full_MapCandidateFrequency.

Next, our group will determine how many times each map one outright, which will be stored in dataframe Map_Winning_Frequency. Since it is impossible to win outright if there was a tie, we will remove cases where ties occurred. The column "Choice" indicated the winner of the vote, and so we will simply calculate how many times each map occurred in that column.

From there we will have two data frames: Full_MapCandidateFrequency and Map_Winning_Frequency. Each have frequency's related to each of the 28 possible map options. These data frames will be joined into a larger dataframe called Full_MapFrequency. Finally, our group will create one last dataframe called Map_Winning_Percentages which will include the Map name, as well as the value of it's winning frequency divided by the number of times it appeared as a candidate.

For the data visualization, we will create a vertical bar chart that plots each maps rate of winning as a possible candidate. The three Maps with the highest bars will be chosen to answer the research qustion of which maps are most likely to win when they are an option. We will also create a supplementary vertical bar chart that plots the number of times the map associated with "Map1" outright and by tie-default versus the map chosen as the "Map2" option.

### Task 1: Data Preparation Phase

```{r}

# Step 1: Combine p1 and p2

CODGames_P1andP2 <- full_join(CODGames_p1_380, CODGames_p2_380)

# Step 2: Select only columns relevant to task 1 research question

CODGames_P1andP2 <- CODGames_P1andP2 %>%
  select(Map1, Map2, Choice, MapVote)

# Step 3: Remove Cases where values are missing

CODGames_P1andP2 <- CODGames_P1andP2 %>%
  filter(Map1 != "")

# Step 4: Convert MapVote into two separate Numeric Columns

CODGames_P1andP2 <- CODGames_P1andP2 %>%
  separate(MapVote, into = c("left", "right"), sep = " to ") %>%
  mutate(
    result_left = as.numeric(left),
    result_right = as.numeric(right)
  )

CODGames_P1andP2$left <- NULL
CODGames_P1andP2$right <- NULL

# Step 5: Check if there was a tie or not in the vote

CODGames_P1andP2 <- CODGames_P1andP2 %>%
  mutate("tie" = ifelse(result_left == result_right, "Yes", "No"))

# Step 6: Correct the names of the maps to account for misspellings/trailing blanks using as_tibble, mutate, and amatch

CODGames_P1andP2 <- CODGames_P1andP2 %>%
  mutate(Map1 = case_when(Map1 %in% c("Collateral", "Collateral Striek", "Collaterol Strike") ~ "Collateral Strike",
                          Map1 == "Deprogam" ~ "Deprogram",
                          Map1 == "Drive-in" ~ "Drive-In",
                          Map1 == "Jungle " ~ "Jungle",
                          Map1 == "Miami " ~ "Miami",
                          Map1 == "Miami Stirke" ~ "Miami Strike",
                          Map1 %in% c("Raid ", "Riad") ~ "Raid",
                          Map1 %in% c("Ruah", "Rush ") ~ "Rush",
                          Map1 == "Zoo " ~ "Zoo",
                          TRUE ~ Map1)) %>%
  mutate(Map2 = case_when(Map2 == "Amrada Strike" ~ "Armada Strike",
                          Map2 == "Collateral" ~ "Collateral Strike",
                          Map2 == "Drive-in" ~ "Drive-In",
                          Map2 %in% c("Miami Sstrike", "Miami Stirke") ~ "Miami Strike",
                          Map2 == "Nuketown '84 Halloween" ~ "Nuketown '84",
                          Map2 == "yamantau" ~ "Yamantau",
                          TRUE ~ Map2)) %>%
  mutate(Choice = case_when(Choice %in% c("APocalypse", "Apocolypse") ~ "Apocalypse",
                            Choice %in% c("Collateral", "Collaterel Strike") ~ "Collateral Strike",
                            Choice == "Deisel" ~ "Diesel",
                            Choice == "Drive-in" ~ "Drive-In",
                            Choice == "Nuketown '84 Halloween" ~ "Nuketown '84",
                            TRUE ~ Choice))
```

### Task 1 - Data Analysis Phase

#### Finding out how many times each Map was a candidate

```{r}

# Step 7: Finding Candidate Frequency for Map1 & Map2, then congregating that information together using left_join

Map1_CandidateFrequency <- CODGames_P1andP2 %>%
  group_by(Map1) %>%
  summarize(count1 = n())

Map2_CandidateFrequency <- CODGames_P1andP2 %>%
  group_by(Map2) %>%
  summarize(count2 = n())

Full_MapCandidateFrequency <- left_join(Map1_CandidateFrequency, Map2_CandidateFrequency, by = c("Map1" = "Map2")) %>%
  mutate(TotalCandidateFrequency = count1 + count2)

Full_MapCandidateFrequency$count1 <- NULL

Full_MapCandidateFrequency$count2 <- NULL

Full_MapCandidateFrequency

```

#### Finding out how many times each map won outright (no ties)

```{r}

# Step 8

Map_Winning_frequency <- CODGames_P1andP2 %>%
  filter(tie == "No") %>%
  group_by(Choice) %>%
  summarize(count = n())

Map_Winning_frequency

```

#### Joining Map winning frequency data with Map candidacy frequency data

```{r}

# Step 9

Full_MapFrequency <- left_join(Full_MapCandidateFrequency, Map_Winning_frequency, by = c("Map1" = "Choice"))

Map_WinningPercentages <- Full_MapFrequency %>%
  mutate(winning_pct = count/TotalCandidateFrequency)

Map_WinningPercentages$count <- NULL
Map_WinningPercentages$TotalCandidateFrequency <- NULL

Map_WinningPercentages

```

### Task 1 - Data Visualization

#### Visualizing winning percentage by Map

```{r}

ggplot(Map_WinningPercentages, aes(x = Map1, y = winning_pct)) +
  geom_bar(stat = "identity", fill = "skyblue", color = "black") +
  labs(title = "Winning Percentage by Map",
       x = "Map",
       y = "Winning Percentage") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

```

From this visualization, we observe that Maps like Raid, Crossroads Strike, and Nuketown '84 have the highest vote winning rates when offered as a choice, whereas maps like Echelon, WMD, and Miami are among the lowest. Therefore to answer the research question Raid, Nuketown '84 and Crossroads Strike are the three maps most likely to win the map vote when they are an option?

#### Visualizing rate of victory by option (Map1, Map2, or Map1 by tie-default)

```{r}

# Step 8: Create Bar Chart Showing Map1 Winning By Tie vs Not, or Map2

# Create New column showing which map won the vote, and if they won by tie

CODGames_P1andP2 <- CODGames_P1andP2 %>%
  mutate(
    MapWins = case_when(
      Map1 == Choice & tie == "No" ~ "Map1 without Tie",
      Map1 == Choice & tie == "Yes" ~ "Map1 with Tie",
      Map2 == Choice ~ "Map2"
    )
  )

# Create Simple Bar Plot for COD Map Choice

counts <- table(CODGames_P1andP2$MapWins)
barplot(counts, main="COD Map Choice",
   xlab="Map Choice", col=rgb(0.8,0.1,0.1,0.6))

```

Based off this Visualization, it appears that the Map2 choice won outright more frequently than Map1, however when Map1's victories both outright and via ties were tabulated together, that number outperformed Map2 win rate.

### Task 2

```{r}

# Change dataframe names to match GenAI Code

maps <- CODMAPS
p1 <- CODGames_p1_380
p2 <- CODGames_p2_380

# Step 1: Standardize correct map names
clean_maps <- maps %>%
  mutate(Name_clean = tolower(str_trim(Name)))



# Step 2: Implement Levenshtein Distance Function
levenshtein_distance <- function(str1, str2) {
  if (is.na(str1) || is.na(str2) || str1 == "" || str2 == "") {
    return(Inf)  # Return a large value if either string is NA or empty
  }
  len1 <- nchar(str1)
  len2 <- nchar(str2)
  str1 <- unlist(strsplit(str1, ""))
  str2 <- unlist(strsplit(str2, ""))
  
  # Initialize matrix
  dp <- matrix(0, nrow = len1 + 1, ncol = len2 + 1)
  for (i in 1:(len1 + 1)) dp[i, 1] <- i - 1
  for (j in 1:(len2 + 1)) dp[1, j] <- j - 1
  
  # Fill matrix
  for (i in 2:(len1 + 1)) {
    for (j in 2:(len2 + 1)) {
      cost <- ifelse(str1[i - 1] == str2[j - 1], 0, 1)
      dp[i, j] <- min(dp[i - 1, j] + 1,       # Deletion
                      dp[i, j - 1] + 1,       # Insertion
                      dp[i - 1, j - 1] + cost) # Substitution
    }
  }
  return(dp[len1 + 1, len2 + 1])
}


# Step 3: Function to Find Closest Map Name
find_closest_match <- function(input_name, correct_names) {
  if (is.na(input_name) || input_name == "") return(NA)
  input_name <- tolower(str_trim(input_name))
  distances <- sapply(correct_names, function(x) levenshtein_distance(input_name, x))
  return(correct_names[which.min(distances)])
}


p1 <- p1 %>%
  mutate(Map1 = ifelse(!is.na(Map1) & Map1 != "", sapply(Map1, find_closest_match, correct_names), NA),
         Map2 = ifelse(!is.na(Map2) & Map2 != "", sapply(Map2, find_closest_match, correct_names), NA),
         Choice = ifelse(!is.na(Choice) & Choice != "", sapply(Choice, find_closest_match, correct_names), NA))

p2 <- p2 %>%
  mutate(Map1 = ifelse(!is.na(Map1) & Map1 != "", sapply(Map1, find_closest_match, correct_names), NA),
         Map2 = ifelse(!is.na(Map2) & Map2 != "", sapply(Map2, find_closest_match, correct_names), NA),
         Choice = ifelse(!is.na(Choice) & Choice != "", sapply(Choice, find_closest_match, correct_names), NA))

# Step 4: Correct Map Names in the Dataset
correct_names <- clean_maps$Name_clean

p1 <- p1 %>%
  mutate(Map1 = ifelse(!is.na(Map1), sapply(Map1, find_closest_match, correct_names), NA),
         Map2 = ifelse(!is.na(Map2), sapply(Map2, find_closest_match, correct_names), NA),
         Choice = ifelse(!is.na(Choice), sapply(Choice, find_closest_match, correct_names), NA))

p2 <- p2 %>%
  mutate(Map1 = ifelse(!is.na(Map1), sapply(Map1, find_closest_match, correct_names), NA),
         Map2 = ifelse(!is.na(Map2), sapply(Map2, find_closest_match, correct_names), NA),
         Choice = ifelse(!is.na(Choice), sapply(Choice, find_closest_match, correct_names), NA))

# Step 5: Combine datasets for Player 1 and Player 2
combined_data <- bind_rows(p1, p2)

# Step 6: Identify map wins
map_wins <- combined_data %>%
  filter(!is.na(Map1) & !is.na(Map2)) %>%
  mutate(Winner = case_when(
    Choice == Map1 & Map1 != Map2 ~ Map1,  # Map1 wins outright
    Choice == Map2 & Map1 != Map2 ~ Map2,  # Map2 wins outright
    Map1 == Map2 ~ Map1                   # Handle tie when Map1 == Map2
  )) %>%
  filter(!is.na(Winner)) %>%
  pivot_longer(cols = c(Map1, Map2), names_to = "MapType", values_to = "Map") %>%
  group_by(Map) %>%
  summarize(Total_Votes = n(),
            Wins = sum(Winner == Map, na.rm = TRUE)) %>%
  mutate(Win_Probability = Wins / Total_Votes) %>%
  left_join(clean_maps, by = c("Map" = "Name_clean"))

# Step 7: Visualization of results
ggplot(map_wins, aes(x = reorder(Name, -Win_Probability), y = Win_Probability)) +
  geom_bar(stat = "identity") +
  coord_flip() +
  labs(title = "Map Win Probabilities (Corrected Names)",
       x = "Map",
       y = "Probability of Winning") +
  theme_minimal()

```

Tool Used: ChatGPT 4

Prompts Provided: 

  Prompt 1: Project Assignment PDF and all data files, + "Complete only task 1. Make sure to account for the edge cases such as mispellings. My suggestion would be to somehow use the correct spellings of the maps that you are given in CODMaps.csv, and somehow compare it to the relevant columns in p1 and p2. Make sure to remember that ties do not count as outright victories as well. We are working in R"

  Prompt 2 (Re-addressing misspellings): "This code doesn't account for mispellings. For example, there are cases where "raid" is mispelled as "riad." I want this code to identify that mistake and correct with it's intended map name. Do this for all mispellings"

  Prompt 3 (After ChatGPT recommended a couple libraries not available in my version of R (stringdist and fuzzyjoin): "Is there anyway you can do it not using a built in function?"

  Prompt 4 (After ChatGPT wrote Levenshtein Distance Algorithm script, but I was given "subscript out of bounds" error): "I'm getting this error?"

  Prompt 4 was the final prompt

Comparison of AI Solution to Group Solution in Task 1: 
In our manual approach, we fixed the map name inconsistencies by explicitly specifying corrections using multiple case_when statements. Specific misspellings and trailing spaces were manually identified and corrected. This approach is straightforward but time-consuming because it requires manually identifying errors and listing all possible variations. The AI-generated solution uses a Levenshtein Distance algorithm to automatically identify and correct map name misspellings. Levenshtein Distance calculates the number of character edits needed to match a string to the correct name. This method is more scalable and efficient for larger datasets since it doesnâ€™t require manually listing every error. In terms of sorting and visualization, the manual final bar chart displays the winning percentages for each map in a vertical bar chart sorted in their default order, which is alphabetical. This default sorting can make it harder to visually identify which maps performed best. The AI-generated code sorts the bar chart in descending order of winning probability using the reorder() function and displays the chart horizontally using coord_flip(). This design improves readability and makes it easier to compare the performance of maps. Lastly, for dealing with map win calculations, the manual code calculates map wins by explicitly filtering for tie situations where Map1 wins by default and Outright wins where the map received more votes. The logic for combining candidate frequency and winning frequency is broken into multiple steps with separate joins and filtering. The AI code integrates the logic for calculating wins, tie handling, and appearances into a single concise workflow using the pivot_longer function to tidy the data and group results efficiently. Overall, the AI-generated code is more automated and scalable, particularly for correcting the errors in the data using Levenshtein Distance. Additionally, The AI improves visual clarity with a sorted and horizontal bar chart, which enhances readability, as well as having a more efficient approach to the data wrangling. Both methods ultimately answer the research question effectively, but the AI-generated code demonstrates improved readability and conciseness.

Who had the more effective solution: Our group, or the AI?

Upon comparison, our group came to the conclusion that the AI solution was a more complex yet more effective method of answering this research question. This was mainly due to the differences in our answers when it came to resolving edge cases featuring misspellings, leading spaces, or misrepresentations of map names. While our code was effective in resolving the singular issues by manually picking out incorrect cases, the AI result provides solution that can be scaled to larger datasets and solve more complex problems.

  


## Task 3

#### Step 1: Combining Player dataframes again so all attributes are available
```{r}

CODGames_P1andP2 <- full_join(CODGames_p1_380, CODGames_p2_380)

```

#### Step 2: Cleaning GameType column

In this step, we resolve some discrepancies with how game type names are written. Certain games are prefaced with "HC - ." These code removes this prefix to consolidate game types into four categories.

```{r}

CODGames_P1andP2 <- CODGames_P1andP2 %>%
  mutate(GameType = case_when(GameType == "HC - TDM" ~ "TDM",
                          GameType == "HC - Hardpoint" ~ "Hardpoint",
                          GameType == "HC - Domination" ~ "Domination",
                          GameType == "HC - Kill Confirmed" ~ "Kill Confirmed",
                          TRUE ~ GameType))

```

#### Step 3: EDA, Analyzing Distributions of GameType, Score, and TotalXP

##### 3.1: TotalXP

```{r}

# TotalXP Summary Statistics

print("TotalXP Summary Statistics")
summary(CODGames_P1andP2$TotalXP)

# DensityPlot for TotalXP

options(scipen = 999)

ggplot(CODGames_P1andP2, aes(x = TotalXP)) +
  geom_density(fill = "blue", alpha = 0.4) +
  labs(title = "Density Plot of TotalXP",
       x = "TotalXP",
       y = "Density") +
  theme_minimal()

```

In this density plot, we see that TotalXP is skewed slightly right. We also observe from the summary statistics that the median and average TotalXP are both right around 15,000, with a range for TotalXP of over 40,000.

#### Step 4:

##### 3.2: Score

```{r}

# Score Summary Statistics

print("Score Summary Statistics")
summary(CODGames_P1andP2$Score)

# DensityPlot for Score

ggplot(CODGames_P1andP2, aes(x = Score)) +
  geom_density(fill = "blue", alpha = 0.4) +
  labs(title = "Density Plot of Score",
       x = "Score",
       y = "Density") +
  theme_minimal()

```

In this density plot, we see that the distribution of Score is also skewed slightly right. Additionally, we observe from the summary statistics that the median and average Score are both right around 2,900, with a range for Score of about 9,600. These statistics are noticeably less than what was observed for TotalXP.

##### 3.3: GameType

```{r}

# Bar Chart for GameType

ggplot(CODGames_P1andP2, aes(x = GameType)) +
  geom_bar(fill = "skyblue", color = "black") +
  labs(title = "Frequency of GameType",
       x = "GameType",
       y = "Count") +
  theme_minimal()

```

In this visualization, we observe that TDM and Hardpoint are the predominant GameTypes among the Player 1 and 2 data available. Between these two types, TDM outnumbers Hardpoint 2:1 in frequency.

##### 3.4 Visualizing Relationship between TotalXP, Score, GameType

For this we will do charts with two lines, Score and TotalXP, facet wrapped by GameType.

```{r}
ggplot(CODGames_P1andP2, aes(x = Score, y = TotalXP)) +
  geom_smooth(color = "blue", method = "loess", se = FALSE) +
  facet_wrap(~ GameType, scales = "free") +
  labs(title = "Relationship between TotalXP, Score and GameType",
       x = "Score",
       y = "TotalXP") +
  theme_minimal()
```

In this visualization, we have plotted Score vs TotalXP when grouped by each category of GameType. In each grouping, we see a strong positive relationship between Score and TotalXP. That being said, in the hardpoint, TotalXP appears to go down once Score exceeds 7500. Since hardpoint is one of the 2 main GameTypes, this will be an interesting dynamic to consider going forward.

#### Step 4: Build model for TotalXP based off Score and GameType

```{r}

model <- lm(TotalXP ~ Score + GameType, data = CODGames_P1andP2)

summary(model)

```

Upon accounting for Score, this model was tasked with answering a research question to determine how TotalXP is affected by GameType. Based off our EDA, as well as the low P-value associated with score, it is clear that Score is a strong indicator of TotalXP, which explains why accounting for this variable was prudent. However, once Score was accounted for, we observe a relatively low R-squared value (~.34) for the relationship between GameType and TotalXP. This model performance result suggests that while Score was a strong indicator of TotalXP, GameType is a relatively poor indicator. Thus, to answer the research question, after accounting for Score, GameType does not considerably affect TotalXP.

## Task 4

Research Question: What factors best contribute to the player winning a match?

## Random Forest Method:

The use of the random forest method will focus on which features will are most important in predicting Win, using the complexity parameter for pruning the tree. They will also provide easy visualizations that help to explain how each of the factors connect to the response variable being studied. The trees can handle complex, nonlinear relationships between the predictors and the outcome. 

### Step 1: Prepare Data

It is necessary to combine both pieces of player data again, and choose which factors will be tested in finding out which of them in most important to the Win variable. This will be accomplished through joining the two datasets, selecting the columns that are needed, and removing unnecessary data from the combined datasets and fixing spelling errors from in the data.

The "Win" column will be created from splitting the "Result" into two columns which will determine if the player had won the match or not. This column and the "Choice" column will be made into factors so they caan be split into the Test and Validation sets.

```{r}
# Part a: Combine player 1 and player 2 data

CODGames_P1andP2 <- full_join(CODGames_p1_380, CODGames_p2_380)

# Step 2: Select columns relevant to task 4 research question

CODGames_P1andP2 <- CODGames_P1andP2 %>%
  select(Choice, Eliminations, Deaths, Score, Damage, PrimaryWeapon, GameType, Result)

# Step 3: Remove Cases where values are missing

CODGames_P1andP2 <- CODGames_P1andP2 %>%
  filter(Choice != "" & PrimaryWeapon != "")

# Step 4: Fix spellings of map choice names

CODGames_P1andP2 <- CODGames_P1andP2 %>%
  mutate(Choice = case_when(Choice %in% c("APocalypse", "Apocolypse") ~ "Apocalypse",
                            Choice %in% c("Collateral", "Collaterel Strike") ~ "Collateral Strike",
                            Choice == "Deisel" ~ "Diesel",
                            Choice == "Drive-in" ~ "Drive-In",
                            Choice == "Nuketown '84 Halloween" ~ "Nuketown '84",
                            TRUE ~ Choice))

# Step 5: Create a new column for player 1 or 2 winning a match from 
# split result column into two to make win column

CODGames_P1andP2 <- CODGames_P1andP2 %>%
  separate(Result, into = c("Result_Player", "Result_Opposing"), sep = "-") %>%
  mutate(
    result_player = as.numeric(Result_Player),
    result_opposing = as.numeric(Result_Opposing)
  )

CODGames_P1andP2 <- CODGames_P1andP2 %>%
  mutate("Win" = ifelse(result_player > result_opposing, "Yes", "No"))

# Step 6: Convert Win and Choice to factor

CODGames_P1andP2$Win <- as.factor(CODGames_P1andP2$Win)

CODGames_P1andP2$Choice <- as.factor(CODGames_P1andP2$Choice)


# Step 7: Perform Training/Validation Split
set.seed(123)
CODGames_P1andP2Ind <- sample(1:nrow(CODGames_P1andP2), floor(0.85*nrow(CODGames_P1andP2)))

CODGames_P1andP2 <- CODGames_P1andP2[, c("Choice", "Eliminations", "Deaths", "Score", "Damage", "PrimaryWeapon", "GameType", "Win")]

#Step 8: Create Train and Validations
Train <- CODGames_P1andP2[CODGames_P1andP2Ind, ]
Validation <- CODGames_P1andP2[-CODGames_P1andP2Ind, ]
```

The complexity parameter and cross-validation error will be used to simplify the tree, and the 1-SE Rule will be applied to help in avoiding overfitting, through selecting a simpler tree with a generalizable error.

### Step 2:  Pruning the Tree
```{r}
#Part a:  Using a complexity parameter (cp) value of 0.001, grow the tree. 
set.seed(123)
fullTree <- rpart(Win ~ ., 
                  method = "class",
                  data = Train,
                  cp = 0.01,
                  xval = 10)

#Part b: Display the cptable
fullTree$cptable
```

### Step 3 - Plot the tree
```{r}
fancyRpartPlot(fullTree, cex = 0.5)
```

### Step 4: Visualize the results of the cross validation procedure. 
```{r}
plotcp(fullTree)
```

### Step 5: What is the optimal value of the complexity parameter based on minimizing the cross validation error? 
```{r}
#Part a: Determine the row of cptable containing smallest CV error
cpRow <- which.min(fullTree$cptable[ , "xerror"])

#Part b: Determine optimal value of cp 
cpChoiceMin <- fullTree$cptable[ , "CP"][cpRow]

#Part c: Display the choice
cpChoiceMin
```

### Step 6: Find the optimal value of the complexity parameter based on the 1se rule
```{r}
#Part a: Determine the row of cptable containing smallest CV error
cpRow <- which.min(fullTree$cptable[ , "xerror"])

# Part b: Calculate min(xerror) + xstd
target <- fullTree$cptable[ , "xerror"][cpRow] +fullTree$cptable[ , "xstd"][cpRow]

#Part c: Determine which xerror values are less than target and select first such value
cpRow1se <- which(fullTree$cptable[ , "xerror"] < target)[1]

cpChoice1se <- fullTree$cptable[ , "CP"][cpRow1se]

#Part d: Display the choice
cpChoice1se
```

### Step 7: Prune the Tree
```{r}
#Part a: Prune the true
prunedTree <- prune(fullTree, cp=cpChoice1se)

#Part b: View the pruned tree
fancyRpartPlot(prunedTree, cex=0.65)
```

### Step 8: Find the validation set accuracy from Pruned Tree
```{r}
#Part a: Obtain the predicted classes
prunedPred <- predict(prunedTree, newdata = Validation,
                      type = "class")
  
#Part b: Calculate the accuracy
mean(prunedPred == Validation$Win)
```

From the results of the tree we can see that the accuracy on the validation as 60.33%, while showing that "Deaths" is the most influential variables for "Win". It illustrates how lower deaths will lead to more wins for the players.

## Support Vector Machines (SVMs) Method:

The support vector machine will use a kernal-based method for classification, assessing the research question through Recursive Feature Elimination and accuracy evaluation from model predictions. It will focus on finding the optimal decision boundary to maximize the margin between whether a player has won a match or not.

### Step 1: Convert factors to numeric for SVM
```{r}
CODGames_P1andP2$Choice <- as.factor(CODGames_P1andP2$Choice)
CODGames_P1andP2$PrimaryWeapon <- as.factor(CODGames_P1andP2$PrimaryWeapon)
```

### Step 2: Split data into train and validation sets
```{r}
set.seed(123)
train_indices <- sample(1:nrow(CODGames_P1andP2), floor(0.85 * nrow(CODGames_P1andP2)))
Train <- CODGames_P1andP2[train_indices, ]
Validation <- CODGames_P1andP2[-train_indices, ]
```

### Step 3: Train SVM Model
```{r}
svm_model <- svm(Win ~ ., data = Train, kernel = "radial")
```

### Step 4: Predict on Validation Set
```{r}
svm_pred <- predict(svm_model, newdata = Validation)
```
## Step 5: Get the most import factor for "Win"
```{r}
#Part a: Fit SVM model with RFE
control <- rfeControl(functions=rfFuncs, method="cv", number=10)
rfe_result <- rfe(Train %>% select(-Win), Train$Win, sizes=1:ncol(Train)-1, rfeControl=control)

#Part b: Get the important features
important_features <- predictors(rfe_result)
important_features
```

### Step 6: Evaluate Accuracy
```{r}
accuracy_svm <- mean(svm_pred == Validation$Win)
accuracy_svm
```

The accuracy found for the SVM method is 66.94%, while allowing better separation between decision boundaries like Win = Yes and Win = No from its nonlinear modeling.


## Analysis of Both Methods:

Both of the methods being used shows that "Deaths" was the most important factor for "Win", from the seven other factors being tested. From the accuracy predictions of each model, we can see that SVM allows for a higher accuracy compared to the random forest model. This is due to the how overfitting is more present in the random forest model, due to the high amount of decision trees being used.
