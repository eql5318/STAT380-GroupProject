---
title: "Group Project"
authors: "Ed Lawrence, Bobby Dodge, Henry Harrison"
date: "2024-12-10"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}

library(tidyverse)
library(ggplot2)
library(randomForest)
library(dplyr)
library(rpart)
library(rattle)
library(e1071)

CODMAPS <- read.csv("CODMaps.csv")
CODGameModes <- read.csv("CODGameModes.csv")
CODGames_p1_380 <- read.csv("CODGames_p1_380.csv")
CODGames_p2_380 <- read.csv("CODGames_p2_380.csv")
```

## Task 1
To determine which maps are most likely to win the map vote when presented as an option, we will follow an approach that addresses both the calculations and potential data quality issues. The first data quality issue we need to address is the missing data in the Map1 and Map2 columns, while the Choice column still contains data. To address this issue, we will remove these observations from the dataset because we cannot accurately assess the map vote without knowing both maps that were presented as options. This ensures that the analysis only considers cases where two maps were available for voting, maintaining the integrity of our calculations for map selection probabilities.  I will cross-check the Map1 and Map2 columns with the correct map names provided in CODMaps.csv. Any misspellings or extra trailing spaces will be corrected programmatically by standardizing the values using string matching techniques such as functions. For each map, we will count the number of times it appeared in either Map1 or Map2. This represents the total opportunities for a map to win a vote. We will also count the amount of times a map received more votes than its competitor. We will identify cases where a vote was tied (indicated by a MapVote value of "tie" or similar) and the map listed in Map1 was chosen as the winner. These will be added to the total wins for Map1. For each map, I will compute the proportion of wins (total wins / total presentations). This will include wins by both higher vote counts and by default tie-breaking rules. We will create a bar chart to visualize the winning probability for each map. The x-axis will represent the maps, and the y-axis will show their winning probabilities. Maps will be sorted by their probabilities to provide a clear comparison.

### Task 1: Data Preparation Phase

```{r}

# Step 1: Combine p1 and p2

CODGames_P1andP2 <- full_join(CODGames_p1_380, CODGames_p2_380)

# Step 2: Select only columns relevant to task 1 research question

CODGames_P1andP2 <- CODGames_P1andP2 %>%
  select(Map1, Map2, Choice, MapVote)

# Step 3: Remove Cases where values are missing

CODGames_P1andP2 <- CODGames_P1andP2 %>%
  filter(Map1 != "")

# Step 4: Convert MapVote into two separate Numeric Columns

CODGames_P1andP2 <- CODGames_P1andP2 %>%
  separate(MapVote, into = c("left", "right"), sep = " to ") %>%
  mutate(
    result_left = as.numeric(left),
    result_right = as.numeric(right)
  )

CODGames_P1andP2$left <- NULL
CODGames_P1andP2$right <- NULL

# Step 5: Check if there was a tie or not in the vote

CODGames_P1andP2 <- CODGames_P1andP2 %>%
  mutate("tie" = ifelse(result_left == result_right, "Yes", "No"))

# Step 6: Correct the names of the maps to account for misspellings/trailing blanks using as_tibble, mutate, and amatch

CODGames_P1andP2 <- CODGames_P1andP2 %>%
  mutate(Map1 = case_when(Map1 %in% c("Collateral", "Collateral Striek", "Collaterol Strike") ~ "Collateral Strike",
                          Map1 == "Deprogam" ~ "Deprogram",
                          Map1 == "Drive-in" ~ "Drive-In",
                          Map1 == "Jungle " ~ "Jungle",
                          Map1 == "Miami " ~ "Miami",
                          Map1 == "Miami Stirke" ~ "Miami Strike",
                          Map1 %in% c("Raid ", "Riad") ~ "Raid",
                          Map1 %in% c("Ruah", "Rush ") ~ "Rush",
                          Map1 == "Zoo " ~ "Zoo",
                          TRUE ~ Map1)) %>%
  mutate(Map2 = case_when(Map2 == "Amrada Strike" ~ "Armada Strike",
                          Map2 == "Collateral" ~ "Collateral Strike",
                          Map2 == "Drive-in" ~ "Drive-In",
                          Map2 %in% c("Miami Sstrike", "Miami Stirke") ~ "Miami Strike",
                          Map2 == "Nuketown '84 Halloween" ~ "Nuketown '84",
                          Map2 == "yamantau" ~ "Yamantau",
                          TRUE ~ Map2)) %>%
  mutate(Choice = case_when(Choice %in% c("APocalypse", "Apocolypse") ~ "Apocalypse",
                            Choice %in% c("Collateral", "Collaterel Strike") ~ "Collateral Strike",
                            Choice == "Deisel" ~ "Diesel",
                            Choice == "Drive-in" ~ "Drive-In",
                            Choice == "Nuketown '84 Halloween" ~ "Nuketown '84",
                            TRUE ~ Choice))
```

### Task 1 - Data Analysis Phase

#### Finding out how many times each Map was a candidate

```{r}

# Step 7: Finding Candidate Frequency for Map1 & Map2, then congregating that information together using left_join

Map1_CandidateFrequency <- CODGames_P1andP2 %>%
  group_by(Map1) %>%
  summarize(count1 = n())

Map2_CandidateFrequency <- CODGames_P1andP2 %>%
  group_by(Map2) %>%
  summarize(count2 = n())

Full_MapCandidateFrequency <- left_join(Map1_CandidateFrequency, Map2_CandidateFrequency, by = c("Map1" = "Map2")) %>%
  mutate(TotalCandidateFrequency = count1 + count2)

Full_MapCandidateFrequency$count1 <- NULL

Full_MapCandidateFrequency$count2 <- NULL

Full_MapCandidateFrequency

```

#### Finding out how many times each map won outright (no ties)

```{r}

# Step 8

Map_Winning_frequency <- CODGames_P1andP2 %>%
  filter(tie == "No") %>%
  group_by(Choice) %>%
  summarize(count = n())

Map_Winning_frequency

```

#### Joining Map winning frequency data with Map candidacy frequency data

```{r}

# Step 9

Full_MapFrequency <- left_join(Full_MapCandidateFrequency, Map_Winning_frequency, by = c("Map1" = "Choice"))

Map_WinningPercentages <- Full_MapFrequency %>%
  mutate(winning_pct = count/TotalCandidateFrequency)

Map_WinningPercentages$count <- NULL
Map_WinningPercentages$TotalCandidateFrequency <- NULL

Map_WinningPercentages

```

### Task 1 - Data Visualization

#### Visualizing winning percentage by Map

```{r}

ggplot(Map_WinningPercentages, aes(x = Map1, y = winning_pct)) +
  geom_bar(stat = "identity", fill = "skyblue", color = "black") +
  labs(title = "Winning Percentage by Map",
       x = "Map",
       y = "Winning Percentage") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

```

From this vizualization, we observe that Maps like Raid, Crossroads Strike, and Nuketown '84 have the highest vote winning rates when offered as a choice, whereas maps like Echelon, WMD, and Miami are among the lowest.

#### Visualizing rate of victory by option (Map1, Map2, or Map1 by tie-default)

```{r}

# Step 8: Create Bar Chart Showing Map1 Winning By Tie vs Not, or Map2

# Create New column showing which map won the vote, and if they won by tie

CODGames_P1andP2 <- CODGames_P1andP2 %>%
  mutate(
    MapWins = case_when(
      Map1 == Choice & tie == "No" ~ "Map1 without Tie",
      Map1 == Choice & tie == "Yes" ~ "Map1 with Tie",
      Map2 == Choice ~ "Map2"
    )
  )

# Create Simple Bar Plot for COD Map Choice

counts <- table(CODGames_P1andP2$MapWins)
barplot(counts, main="COD Map Choice",
   xlab="Map Choice", col=rgb(0.8,0.1,0.1,0.6))

```

Based off this Visualization, it appears that the Map2 choice won outright more frequently than Map1, however when Map1's victories both outright and via ties were tabulated together, that number outperformed Map2 win rate.

### Task 2

```{r}

library(dplyr)
library(ggplot2)

# Step 1: Load the datasets
p1_data <- CODGames_p1_380
p2_data <- CODGames_p2_380

# Step 2: Inspect data structure and summary
str(p1_data)
str(p2_data)

# Step 3: Data cleaning
# Remove rows with missing values in critical columns
p1_cleaned <- p1_data %>% filter(!is.na(Map1), !is.na(Map2), !is.na(MapVote))
p2_cleaned <- p2_data %>% filter(!is.na(Map1), !is.na(Map2), !is.na(MapVote))

# Standardize map names by trimming whitespaces and converting to lowercase
p1_cleaned <- p1_cleaned %>%
  mutate(
    Map1 = tolower(trimws(Map1)),
    Map2 = tolower(trimws(Map2)),
    Choice = tolower(trimws(Choice))
  )

p2_cleaned <- p2_cleaned %>%
  mutate(
    Map1 = tolower(trimws(Map1)),
    Map2 = tolower(trimws(Map2)),
    Choice = tolower(trimws(Choice))
  )

# Step 4: Combine datasets
combined_data <- bind_rows(p1_cleaned, p2_cleaned)


# Step 5: Calculate win probabilities with tie handling

# Identify outright wins (exclude ties where Map1 was chosen by default)
outright_wins <- combined_data %>%
  filter(MapVote != "tie" | Choice != Map1) %>%
  group_by(Choice) %>%
  summarise(wins = n()) %>%
  rename(map = Choice)

# Count total appearances for each map (regardless of ties)
appearances <- combined_data %>%
  pivot_longer(cols = c(Map1, Map2), names_to = "position", values_to = "map") %>%
  group_by(map) %>%
  summarise(appearances = n())

# Merge wins and appearances to calculate probabilities
map_probabilities <- appearances %>%
  left_join(outright_wins, by = "map") %>%
  mutate(
    wins = ifelse(is.na(wins), 0, wins),  # Handle maps with no outright wins
    win_probability = wins / appearances
  )

# Step 6: Visualization (unchanged)
map_probabilities <- map_probabilities %>%
  arrange(desc(win_probability))

ggplot(map_probabilities, aes(x = reorder(map, -win_probability), y = win_probability)) +
  geom_bar(stat = "identity", fill = "steelblue") +
  labs(
    title = "Win Probability of Each Map (Excluding Default Wins)",
    x = "Map Name",
    y = "Win Probability"
  ) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

```

## Task 3

#### Step 1: Combining Player dataframes again so all attributes are available
```{r}

CODGames_P1andP2 <- full_join(CODGames_p1_380, CODGames_p2_380)

```

#### Step 2: Cleaning GameType column

In this step, we resolve some discrepancies with how game type names are written. Certain games are prefaced with "HC - ." These code removes this prefix to consolidate game types into four categories.

```{r}

CODGames_P1andP2 <- CODGames_P1andP2 %>%
  mutate(GameType = case_when(GameType == "HC - TDM" ~ "TDM",
                          GameType == "HC - Hardpoint" ~ "Hardpoint",
                          GameType == "HC - Domination" ~ "Domination",
                          GameType == "HC - Kill Confirmed" ~ "Kill Confirmed",
                          TRUE ~ GameType))

```

#### Step 3: EDA, Analyzing Distributions of GameType, Score, and TotalXP

##### 3.1: TotalXP

```{r}

# TotalXP Summary Statistics

print("TotalXP Summary Statistics")
summary(CODGames_P1andP2$TotalXP)

# DensityPlot for TotalXP

options(scipen = 999)

ggplot(CODGames_P1andP2, aes(x = TotalXP)) +
  geom_density(fill = "blue", alpha = 0.4) +
  labs(title = "Density Plot of TotalXP",
       x = "TotalXP",
       y = "Density") +
  theme_minimal()

```

In this density plot, we see that TotalXP is skewed slightly right. We also observe from the summary statistics that the median and average TotalXP are both right around 15,000, with a range for TotalXP of over 40,000.

#### Step 4:

##### 3.2: Score

```{r}

# Score Summary Statistics

print("Score Summary Statistics")
summary(CODGames_P1andP2$Score)

# DensityPlot for Score

ggplot(CODGames_P1andP2, aes(x = Score)) +
  geom_density(fill = "blue", alpha = 0.4) +
  labs(title = "Density Plot of Score",
       x = "Score",
       y = "Density") +
  theme_minimal()

```

In this density plot, we see that the distribution of Score is also skewed slightly right. Additionally, we observe from the summary statistics that the median and average Score are both right around 2,900, with a range for Score of about 9,600. These statistics are noticeably less than what was observed for TotalXP.

##### 3.3: GameType

```{r}

# Bar Chart for GameType

ggplot(CODGames_P1andP2, aes(x = GameType)) +
  geom_bar(fill = "skyblue", color = "black") +
  labs(title = "Frequency of GameType",
       x = "GameType",
       y = "Count") +
  theme_minimal()

```

In this visualization, we observe that TDM and Hardpoint are the predominant GameTypes among the Player 1 and 2 data available. Between these two types, TDM outnumbers Hardpoint 2:1 in frequency.

##### 3.4 Visualizing Relationship between TotalXP, Score, GameType

For this we will do charts with two lines, Score and TotalXP, facet wrapped by GameType.

```{r}
ggplot(CODGames_P1andP2, aes(x = Score, y = TotalXP)) +
  geom_smooth(color = "blue", method = "loess", se = FALSE) +
  facet_wrap(~ GameType, scales = "free") +
  labs(title = "Relationship between TotalXP, Score and GameType",
       x = "Score",
       y = "TotalXP") +
  theme_minimal()
```

In this visualization, we have plotted Score vs TotalXP when grouped by each category of GameType. In each grouping, we see a strong positive relationship between Score and TotalXP. That being said, in the hardpoint, TotalXP appears to go down once Score exceeds 7500. Since hardpoint is one of the 2 main GameTypes, this will be an interesting dynamic to consider going forward.

#### Step 4: Build model for TotalXP based off Score and GameType

```{r}

model <- lm(TotalXP ~ Score + GameType, data = CODGames_P1andP2)

summary(model)

```

Upon accounting for Score, this model was tasked with answering a research question to determine how TotalXP is affected by GameType. Based off our EDA, as well as the low P-value associated with score, it is clear that Score is a strong indicator of TotalXP, which explains why accounting for this variable was prudent. However, once Score was accounted for, we observe a relatively low R-squared value (~.34) for the relationship between GameType and TotalXP. This model performance result suggests that while Score was a strong indicator of TotalXP, GameType is a relatively poor indicator. Thus, to answer the research question, after accounting for Score, GameType does not considerably affect TotalXP.

## Task 4

Research Question: What factors best contribute to the player winning a match?

Methods used: Random Forest, Support Vector Machines

## Random Forest Method:

### Step 1: Prepare Data

```{r}
# Part a: Combine player 1 and player 2 data

CODGames_P1andP2 <- full_join(CODGames_p1_380, CODGames_p2_380)

# Step 2: Select columns relevant to task 4 research question

CODGames_P1andP2 <- CODGames_P1andP2 %>%
  select(Choice, Eliminations, Deaths, Score, Damage, PrimaryWeapon, GameType, Result)

# Step 3: Remove Cases where values are missing

CODGames_P1andP2 <- CODGames_P1andP2 %>%
  filter(Choice != "" & PrimaryWeapon != "")

# Step 4: Fix spellings of map choice names

CODGames_P1andP2 <- CODGames_P1andP2 %>%
  mutate(Choice = case_when(Choice %in% c("APocalypse", "Apocolypse") ~ "Apocalypse",
                            Choice %in% c("Collateral", "Collaterel Strike") ~ "Collateral Strike",
                            Choice == "Deisel" ~ "Diesel",
                            Choice == "Drive-in" ~ "Drive-In",
                            Choice == "Nuketown '84 Halloween" ~ "Nuketown '84",
                            TRUE ~ Choice))

# Step 5: Create a new column for player 1 or 2 winning a match from 
# split result column into two to make win column

CODGames_P1andP2 <- CODGames_P1andP2 %>%
  separate(Result, into = c("Result_Player", "Result_Opposing"), sep = "-") %>%
  mutate(
    result_player = as.numeric(Result_Player),
    result_opposing = as.numeric(Result_Opposing)
  )

CODGames_P1andP2 <- CODGames_P1andP2 %>%
  mutate("Win" = ifelse(result_player > result_opposing, "Yes", "No"))

# Step 6: Convert Win and Choice to factor

CODGames_P1andP2$Win <- as.factor(CODGames_P1andP2$Win)

CODGames_P1andP2$Choice <- as.factor(CODGames_P1andP2$Choice)


# Step 7: Perform Training/Validation Split
set.seed(123)
CODGames_P1andP2Ind <- sample(1:nrow(CODGames_P1andP2), floor(0.85*nrow(CODGames_P1andP2)))

CODGames_P1andP2 <- CODGames_P1andP2[, c("Choice", "Eliminations", "Deaths", "Score", "Damage", "PrimaryWeapon", "GameType", "Win")]

#Step 8: Create Train and Validations
Train <- CODGames_P1andP2[CODGames_P1andP2Ind, ]
Validation <- CODGames_P1andP2[-CODGames_P1andP2Ind, ]
```

### Step 2:  Pruning the Tree
```{r}
#Part a:  Using a complexity parameter (cp) value of 0.001, grow the tree. 
set.seed(123)
fullTree <- rpart(Win ~ ., 
                  method = "class",
                  data = Train,
                  cp = 0.01,
                  xval = 10)

#Part b: Display the cptable
fullTree$cptable
```

### Step 3 - Plot the tree
```{r}
fancyRpartPlot(fullTree, cex = 0.5)
```

### Step 4: Visualize the results of the cross validation procedure. 
```{r}
plotcp(fullTree)
```

### Step 5: What is the optimal value of the complexity parameter based on minimizing the cross validation error? 
```{r}
#Part a: Determine the row of cptable containing smallest CV error
cpRow <- which.min(fullTree$cptable[ , "xerror"])

#Part b: Determine optimal value of cp 
cpChoiceMin <- fullTree$cptable[ , "CP"][cpRow]

#Part c: Display the choice
cpChoiceMin
```

### Step 6: Find the optimal value of the complexity parameter based on the 1se rule
```{r}
#Part a: Determine the row of cptable containing smallest CV error
cpRow <- which.min(fullTree$cptable[ , "xerror"])

# Part b: Calculate min(xerror) + xstd
target <- fullTree$cptable[ , "xerror"][cpRow] +fullTree$cptable[ , "xstd"][cpRow]

#Part c: Determine which xerror values are less than target and select first such value
cpRow1se <- which(fullTree$cptable[ , "xerror"] < target)[1]

cpChoice1se <- fullTree$cptable[ , "CP"][cpRow1se]

#Part d: Display the choice
cpChoice1se
```

### Step 7: Prune the Tree
```{r}
#Part a: Prune the true
prunedTree <- prune(fullTree, cp=cpChoice1se)

#Part b: View the pruned tree
fancyRpartPlot(prunedTree, cex=0.65)
```

### Step 8: Find the validation set accuracy from Pruned Tree
```{r}
#Part a: Obtain the predicted classes
prunedPred <- predict(prunedTree, newdata = Validation,
                      type = "class")
  
#Part b: Calculate the accuracy
mean(prunedPred == Validation$Win)

```
## Support Vector Machines (SVMs) Method:

### Step 1: Convert factors to numeric for SVM
```{r}
CODGames_P1andP2$Choice <- as.factor(CODGames_P1andP2$Choice)
CODGames_P1andP2$PrimaryWeapon <- as.factor(CODGames_P1andP2$PrimaryWeapon)
```

### Step 2: Split data into train and validation sets
```{r}
set.seed(123)
train_indices <- sample(1:nrow(CODGames_P1andP2), floor(0.85 * nrow(CODGames_P1andP2)))
Train <- CODGames_P1andP2[train_indices, ]
Validation <- CODGames_P1andP2[-train_indices, ]
```

### Step 3: Train SVM Model
```{r}
svm_model <- svm(Win ~ ., data = Train, kernel = "radial")
```

### Step 4: Predict on Validation Set
```{r}
svm_pred <- predict(svm_model, newdata = Validation)
```

### Step 5: Evaluate Accuracy
```{r}
accuracy_svm <- mean(svm_pred == Validation$Win)
accuracy_svm
```
